{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# problem1: my rolling first target = last x_array, but in tf target is later\n",
    "# problem2: my roll deletes values if not enough window, but tf just shrinks window\n",
    "# roll = convert each row to group of rows\n",
    "# rolling x: each element gets array of self and history_size-1 previous\n",
    "# if element has not enough previous - we delete this element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([3., 4., 5., 6.]), array([4., 5., 6., 7.]),\n",
       "       array([5., 6., 7., 8.]), array([6., 7., 8.]), array([7., 8.]),\n",
       "       array([8.]), array([], dtype=float64)], dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils_lstm as utils_lstm\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "tf.random.set_seed(13)\n",
    "\n",
    "DATALEN = 100#12#4000#000\n",
    "#c = self.conf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "ser1=pd.Series({'f1':'2018-02-13 08:30:00', 'f2':0, 'f3': 0, 'f4':0.5})\n",
    "ser2=pd.Series({'f1':'2018-02-13 08:31:00', 'f2':1, 'f3':-1, 'f4':1.5})\n",
    "ser3=pd.Series({'f1':'2018-02-13 08:32:00', 'f2':2, 'f3':-2, 'f4':2.5})\n",
    "ser4=pd.Series({'f1':'2018-02-13 08:33:00', 'f2':3, 'f3':-3, 'f4':3.5})\n",
    "ser5=pd.Series({'f1':'2018-02-13 08:34:00', 'f2':4, 'f3':-4, 'f4':4.5})\n",
    "ser6=pd.Series({'f1':'2018-02-13 08:35:00', 'f2':5, 'f3':-5, 'f4':5.5})\n",
    "ser7=pd.Series({'f1':'2018-02-13 08:36:00', 'f2':6, 'f3':-6, 'f4':6.5})\n",
    "ser8=pd.Series({'f1':'2018-02-13 08:37:00', 'f2':7, 'f3':-7, 'f4':7.5})\n",
    "ser9=pd.Series({'f1':'2018-02-13 08:38:00', 'f2':8, 'f3':-8, 'f4':8.5})\n",
    "df = pd.DataFrame([ser1,ser2,ser3,ser4,ser5,ser6,ser7,ser8,ser9])\n",
    "df['f1'] = pd.to_datetime(df['f1'], errors='coerce')\n",
    "train_df = df.set_index(df['f1']).drop(columns=['f1'])\n",
    "\n",
    "def roll_arr_same_size(arr, back_window, fwd_window, step=1, mode='back'):\n",
    "    data = []\n",
    "    for i in range(back_window-1,arr.shape[0]-fwd_window+1): # for in range(9): 0 1 ... 8\n",
    "        if mode=='back':\n",
    "            good_rowids = [el for el in range(i-back_window+1, i+1, step)] # i=2/h_s=3: (2-3+1,2+1,1); [v for v in range(0, 3, 1)] -> [0, 1, 2]\n",
    "            data.append(arr[good_rowids])\n",
    "        elif mode=='fwd':   \n",
    "            good_rowids = [el for el in range(i, i+fwd_window, step)] # i=2/h_s=3: (2-3+1,2+1,1); [v for v in range(0, 3, 1)] -> [0, 1, 2]\n",
    "            data.append(arr[good_rowids]) #train_df.values[[0,1,2,3]] # get first 4 rows\n",
    "    return np.array(data)    \n",
    "\n",
    "\n",
    "def prepare_data(train_df): # norm np.arrays\n",
    "    step = 1\n",
    "    BUFFER_SIZE = 1000\n",
    "    BATCH_SIZE = 1\n",
    "    dataset = train_df.values\n",
    "    #TRAIN_SPLIT = 4; \n",
    "    past_history = 3; \n",
    "    future_target = 4\n",
    "    x_array = dataset[:, 1:]\n",
    "    y_array = dataset[:, 0]\n",
    "    \n",
    "    x_train_multi = roll_arr_same_size(arr=x_array, back_window=past_history, fwd_window=future_target, step=step, mode='back')\n",
    "    y_train_multi = roll_arr_same_size(arr=y_array, back_window=past_history, fwd_window=future_target, step=step, mode='fwd')\n",
    "    train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "    train_data_multi = train_data_multi.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "    x_val_multi = x_train_multi\n",
    "    y_val_multi = y_train_multi\n",
    "    val_data_multi = train_data_multi\n",
    "\n",
    "    return y_train_multi #x_train_multi.shape,y_train_multi.shape#, y_train_multi  #x_train_multi#,y_val_multi#, y_train_multi\n",
    "\n",
    "prepare_data(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "range expected at most 3 arguments, got 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7f33b658febe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: range expected at most 3 arguments, got 4"
     ]
    }
   ],
   "source": [
    "range(0,1,6,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[v for v in range(0, 2, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('x=',prepare_data(train_df)[0],'\\n','y=',prepare_data(train_df)[1])\n",
    "#train_df.index\n",
    "\n",
    "# history_size = 2\n",
    "# target_size = 1\n",
    "# rolling x: each element gets array of self and history_size-1 previous\n",
    "# if element has not enough previous - we delete this element\n",
    "#               v    v   v   v   v    v   v    v   - only they have own roll ()\n",
    "#     f2: |0   -1 | -2  -3  -4  -5 | -6  -7 | -8\n",
    "#     f3: |0.5 1.5| 2.5 3.5 4.5 5.5| 6.5 7.5| 8.5\n",
    "#         | rol1  |  ...           |  rol7  | \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_multi = prepare_data(train_df)\n",
    "# for x, y in train_data_multi.take(1):\n",
    "#     print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.to_datetime(pd.DataFrame([['2018-02-13 08:30:00'], ['2018-02-13 09:31:00'], ['2018-02-13 10:32:00'], ['2018-02-13 11:33:00'], ['2018-02-13 08:34:00']], columns=['date'])['date'], errors='coerce')\n",
    "df['val'] = np.random.randn(len(df))\n",
    "#df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "df.index = df['date']\n",
    "df = df.drop(columns=['date'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.to_datetime(pd.date_range('2018-02-13', periods=3, freq='MIN', name='date'), errors='coerce') # freq='T'\n",
    "col1 = np.random.randn(len(dates))\n",
    "pd.DataFrame({'activity':col1}, index=dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "ser1=pd.Series({'f1':'2018-02-13 08:30:00', 'f2':0, 'f3': 0, 'f4':0.5})\n",
    "ser2=pd.Series({'f1':'2018-02-13 08:31:00', 'f2':1, 'f3':-1, 'f4':1.5})\n",
    "ser3=pd.Series({'f1':'2018-02-13 08:32:00', 'f2':2, 'f3':-2, 'f4':2.5})\n",
    "ser4=pd.Series({'f1':'2018-02-13 08:33:00', 'f2':3, 'f3':-3, 'f4':3.5})\n",
    "ser5=pd.Series({'f1':'2018-02-13 08:34:00', 'f2':4, 'f3':-4, 'f4':4.5})\n",
    "ser6=pd.Series({'f1':'2018-02-13 08:35:00', 'f2':5, 'f3':-5, 'f4':5.5})\n",
    "ser7=pd.Series({'f1':'2018-02-13 08:36:00', 'f2':6, 'f3':-6, 'f4':6.5})\n",
    "ser8=pd.Series({'f1':'2018-02-13 08:37:00', 'f2':7, 'f3':-7, 'f4':7.5})\n",
    "ser9=pd.Series({'f1':'2018-02-13 08:38:00', 'f2':8, 'f3':-8, 'f4':8.5})\n",
    "df = pd.DataFrame([ser1,ser2,ser3,ser4,ser5,ser6,ser7,ser8,ser9])\n",
    "df['f1'] = pd.to_datetime(df['f1'], errors='coerce')\n",
    "train_df = df.set_index(df['f1']).drop(columns=['f1'])\n",
    "train_df = train_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "newrow = [10,20,30]\n",
    "A = np.vstack([newrow,train_df])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[v for v in range(0, 5, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2,2.4],[3,4,5]])\n",
    "y = np.full((0,x.shape[1]),0)\n",
    "np.vstack([y,x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     new_rows = np.full((past_history-1,x_array.shape[1]), 0) # generate empty rows at start\n",
    "#     x_array_prepanded = np.vstack([new_rows,x_array])\n",
    "    \n",
    "#     new_targets = np.full((future_target-1,1), 0).reshape(-1) # generate empty rows at start\n",
    "#     print(new_targets.shape, y_array.shape)\n",
    "#     y_array_expanded = np.vstack([y_array,new_targets])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     x_train_multi, y_train_multi = multivariate_data(\n",
    "#         x_array,   y_array, \n",
    "#         start_index = 0,  end_index = x_array.shape[0]+1,\n",
    "#         history_size = past_history, target_size = future_target, \n",
    "#         step = step,\n",
    "#     )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def multivariate_data(dataset, target, start_index, end_index, history_size, target_size, step, single_step=False):\n",
    "#     data = []; labels = []\n",
    "#     start_index = start_index + history_size\n",
    "#     if end_index is None: end_index = len(dataset) - target_size\n",
    "#     for i in range(start_index, end_index):\n",
    "#         indices = range(i-history_size, i, step)\n",
    "#         data.append(dataset[indices])\n",
    "#         if single_step: labels.append(target[i+target_size])\n",
    "#         else: labels.append(target[i:i+target_size])\n",
    "#     return np.array(data), np.array(labels)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
