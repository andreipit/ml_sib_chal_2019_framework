{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0) mini config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FOLDER = 'v00_original'\n",
    "TRAIN_FILENAME = 'train.pkl'\n",
    "TEST_FILENAME = 'test.pkl'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) libs and consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user01\\\\Desktop\\\\sibur-production\\\\input\\\\activity-atactic'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os,sys,inspect,pickle #;sys.exit(sys.path) # sys.exit(np.array([5,52,12]))\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "gragrandparentdir = os.path.dirname(os.path.dirname(os.path.dirname(currentdir))) \n",
    "#sys.path.insert(0,gragrandparentdir) # pipeline-template\n",
    "import time ;tic = time.time() #print(time.time()-tic,'sec')\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import config\n",
    "#import kglpipe\n",
    "#path = gragrandparentdir + kglpipe.myconfig['PATH'] + INPUT_FOLDER # path = os.path.join(gragrandparentdir, kglpipe.myconfig['PATH']+INPUT_FOLDER)\n",
    "parentdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (463058, 60) test (103651, 56) activity_test_target (85891, 0)\n"
     ]
    }
   ],
   "source": [
    "train_data = pickle.load( open(os.path.join(parentdir, INPUT_FOLDER, TRAIN_FILENAME), \"rb\"))\n",
    "test_data = pickle.load( open(os.path.join(parentdir, INPUT_FOLDER, TEST_FILENAME), \"rb\"))\n",
    "activity_test_target = pd.read_csv(os.path.join(parentdir, INPUT_FOLDER, \"activity_test_timestamps.csv\"), index_col=\"date\", parse_dates=[\"date\"])\n",
    "print('train',train_data.shape, 'test',test_data.shape, 'activity_test_target',activity_test_target.shape)#, 'atactic_test_target',atactic_test_target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Timestamp('2018-02-13 08:30:00')] [Timestamp('2018-12-31 22:07:00')]\n",
      "[Timestamp('2019-01-01 00:30:00')] [Timestamp('2019-03-14 00:00:00')]\n"
     ]
    }
   ],
   "source": [
    "print(list(train_data.index)[:1],list(train_data.index)[-1:])\n",
    "print(list(test_data.index)[:1],list(test_data.index)[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-01-01 00:30:00')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) update\n",
    "    step 1 'train' -----------------------------------------------------------------\n",
    "    (463058, 60)  train           with 4 targets           (feb2018-dec2018)\n",
    "    (463058, 4)   train_targets  (activity has 308313 not nulls)\n",
    "    (103651, 56)  test           without 4 targets         (jan2019-mar2019)\n",
    "    (566709, 55)  data           without 4 targets and f28\n",
    "                   +\n",
    "    (566709, 825) all_features    has its unique 825 (55x3x5) columns, generated from data\n",
    "                   ||\n",
    "    (566709, 880) full_data = data + all_features = without 4 targets and f28\n",
    "\n",
    "    (463058, 881)  activity_train_with_nulls = train_targets[[\"activity\"]] + full_data - rows\n",
    "                               463058 x1                       566709 x880  \n",
    "\n",
    "    (300737, 881) activity_train  (without rows with any NaN) save as train.pkl\n",
    "    (103651, 880) activity_test  = full_data from jan2019 => useless! save as test_useless.pkl\n",
    "    \n",
    "    step 2 'test' -----------------------------------------------------------------\n",
    "    (85891,    0) activity_test_target (empty csv with dates: jan2019-mar2019)\n",
    "                    + (join, fillna)\n",
    "    (566709, 880) full_data (see in top)\n",
    "                    ||\n",
    "    (85891,  880) test_activity_data  => real test! save as test.pkl\n",
    "    \n",
    "    conclusion: use only activity, add 825 cols to train, delete null rows and col f28\n",
    "        * for testing - predict full_data from jan2019\n",
    "        * for trainig - split activity_data on train/dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data (566709, 56)\n",
      "train_targets (463058, 4)\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([train_data[test_data.columns], test_data]) ;print('data',data.shape) # use all columns except 4 targets\n",
    "train_targets = train_data[[\"activity\", \"atactic_1\", \"atactic_2\", \"atactic_3\"]].copy() ;print('train_targets',train_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308313 rows without any null in whole row\n"
     ]
    }
   ],
   "source": [
    "series = train_targets[['activity']].notnull().all(axis=1)\n",
    "print(len(series[series==True]), 'rows without any null in whole row') # 300759 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Val1</th>\n",
       "      <th>Val2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-02-24 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-24 01:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-24 02:00:00</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-24 03:00:00</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-24 04:00:00</th>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Val1  Val2\n",
       "Date                           \n",
       "2015-02-24 00:00:00   0.0   1.0\n",
       "2015-02-24 01:00:00   1.0   3.0\n",
       "2015-02-24 02:00:00   3.0   5.0\n",
       "2015-02-24 03:00:00   5.0   7.0\n",
       "2015-02-24 04:00:00   7.0   9.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "rng = pd.date_range('2015-02-24', periods=5, freq='H') # freq='T'\n",
    "df = pd.DataFrame({ 'Date': rng, 'Val1': range(len(rng)), 'Val2': range(1,len(rng)+1) })\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "df.index = df['Date']\n",
    "df = df.drop(columns=['Date'])\n",
    "#     Date                  Val1 Val2  \n",
    "#     2015-02-24 00:00:00   0     1\n",
    "#     2015-02-24 01:00:00   1     2\n",
    "#     2015-02-24 02:00:00   2     3\n",
    "#     2015-02-24 03:00:00   3     4\n",
    "#     2015-02-24 04:00:00   4     5\n",
    "df.rolling('120MIN').aggregate('sum')\n",
    "#     Date                 Val1    Val2\n",
    "#     2015-02-24 00:00:00   0.0    1.0 # has no previous, but != NaN, cause date\n",
    "#     2015-02-24 01:00:00   1.0    3.0 # currVal1 = 1; prev = 0; sum = 1\n",
    "#     2015-02-24 02:00:00   3.0    5.0 # currVal1 = 2; prev = 1; sum = 3\n",
    "#     2015-02-24 03:00:00   5.0    7.0\n",
    "#     2015-02-24 04:00:00   7.0    9.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 825 new cols from joineddata\n",
    "#data.drop(['f28','f25','f42'], axis=1, inplace=True)\n",
    "data.drop(\"f28\", axis=1, inplace=True)\n",
    "#ACOLS = [\"atactic_1\", \"atactic_2\", \"atactic_3\"]\n",
    "#not_null_atactic = train_targets.loc[train_targets[ACOLS].notnull().all(axis=1), ACOLS] ;print(not_null_atactic.shape)\n",
    "PERIODS = ['55MIN']#['1D', '4D', '25D', '45D', '155D']#[\"5H\", \"4H\", \"6H\"]#[\"1H\", \"3H\", \"6H\"]\n",
    "AGGREGATES = [\"mean\", \"median\", \"std\", \"max\", \"min\"]\n",
    "#PERIODS = [\"3H\"]\n",
    "#AGGREGATES = [\"mean\"]\n",
    "all_features = []\n",
    "for period in tqdm.tqdm_notebook(PERIODS):\n",
    "    for agg in AGGREGATES:\n",
    "        print(period,agg,end=',')\n",
    "        rolling_features = data.rolling(period).aggregate(agg)\n",
    "        rolling_features.rename(lambda x: \"_\".join([x, period, agg]), axis=1, inplace=True)\n",
    "        all_features.append(rolling_features)\n",
    "all_features = pd.concat(all_features, axis=1) \n",
    "print('all_features',all_features.shape) #825/5/3 = 55 #15 new cols for each of 55 features \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_data (566709, 56)\n"
     ]
    }
   ],
   "source": [
    "full_data = data.join(all_features)\n",
    "#full_data = data\n",
    "print('full_data',full_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activity_train_with_nulls (463058, 57)\n"
     ]
    }
   ],
   "source": [
    "# add col 'activity' from train to our data (train+test joined generated). 463058, cause in train so\n",
    "activity_train_with_nulls = train_targets[[\"activity\"]].join(full_data.shift(6, freq=\"H\")) # add 6 hours empty rows to start, delete last 6 hours rows\n",
    "print('activity_train_with_nulls',activity_train_with_nulls.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133014 rows without any null in whole row\n"
     ]
    }
   ],
   "source": [
    "series = activity_train_with_nulls.notnull().all(axis=1)\n",
    "print(len(series[series==True]), 'rows without any null in whole row') # 300759 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activity_train (133014, 57)\n"
     ]
    }
   ],
   "source": [
    "activity_train = activity_train_with_nulls[activity_train_with_nulls.notnull().all(axis=1)]\n",
    "print('activity_train',activity_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activity_test (103651, 56)\n"
     ]
    }
   ],
   "source": [
    "activity_test = full_data[full_data.index >= test_data.index[0]]\n",
    "print('activity_test',activity_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_activity_data (85891, 56)\n"
     ]
    }
   ],
   "source": [
    "test_activity_data = activity_test_target.join(full_data.shift(6, freq=\"H\")).ffill() # Synonym for DataFrame.fillna() with method='ffill'.\n",
    "print('test_activity_data',test_activity_data.shape) # test_activity_data (85891, 880)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.148508787155151 sec\n"
     ]
    }
   ],
   "source": [
    "activity_train.to_pickle(os.path.join(currentdir, \"train.pkl\"))\n",
    "activity_test.to_pickle(os.path.join(currentdir, \"test_useless.pkl\"))\n",
    "test_activity_data.to_pickle(os.path.join(currentdir, \"test.pkl\"))\n",
    "\n",
    "print(time.time()-tic,'sec') # 173.91042184829712 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# tic = time.time() \n",
    "# train_fun = pickle.load( open(os.path.join(currentdir, TRAIN_FILENAME+FORMAT), \"rb\"))\n",
    "# test_fun = pickle.load( open(os.path.join(currentdir, TEST_FILENAME+FORMAT), \"rb\"))\n",
    "# print('train_fun',train_fun.shape, 'test_fun',test_fun.shape)#, 'activity_test_timestamps',activity_test_timestamps.shape, 'atactic_test_timestamps',atactic_test_timestamps.shape)\n",
    "# # train_fun (300737, 881) test_fun (103651, 880)\n",
    "# print(time.time()-tic,'sec') # 27 sec\n",
    "# # Split\n",
    "# tr_data = train_fun[:\"2018-10-13\"]\n",
    "# cv_data = train_fun[\"2018-10-14\":]\n",
    "# print('tr_data', tr_data.shape, 'cv_data',cv_data.shape) # tr_data (216400, 881) cv_data (84337, 881)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
